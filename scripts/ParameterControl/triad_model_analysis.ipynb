{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1d48da",
   "metadata": {},
   "source": [
    "# Triad Model Parameter Control and Sensitivity Analysis\n",
    "\n",
    "This notebook demonstrates parameter control and sensitivity analysis for a triad model system with multiplicative noise. It covers simulation, score function estimation, response matrix computation, optimization, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b211171",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"../..\")\n",
    "Pkg.instantiate()\n",
    "\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using StatsBase\n",
    "using GLMakie\n",
    "using CairoMakie\n",
    "using QuadGK\n",
    "using Base.Threads\n",
    "using ProgressBars\n",
    "using KernelDensity\n",
    "using HDF5\n",
    "using Flux\n",
    "using BSON\n",
    "using MarkovChainHammer\n",
    "using ClustGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae463059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Triad Model System Definition ---\n",
    "const L11 = -2.0; const L12 = 0.2; const L13 = 0.1; const g2 = 0.6; const g3 = 0.4;\n",
    "const s2_param = 1.2; const s3 = 0.8; const II = 1.0; const ϵ = 0.1\n",
    "const a = L11 + ϵ * ( (II^2 * s2_param^2) / (2 * g2^2) - (L12^2) / g2 - (L13^2) / g3 )\n",
    "const b = -2 * (L12 * II) / g2 * ϵ\n",
    "const c = (II^2) / g2 * ϵ\n",
    "const B = -(II * s2_param) / g2 * sqrt(ϵ)\n",
    "const A = -(L12 * B) / II\n",
    "const s_noise = (L13 * s3) / g3 * sqrt(ϵ)\n",
    "const F_tilde = (A * B) / 2\n",
    "const params_triad = [a, b, c, F_tilde, A, B, s_noise]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc2786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Drift and Noise Functions ---\n",
    "F(x, t; p=params_triad) = [-p[4] + p[1] * x[1] + p[2] * x[1]^2 - p[3] * x[1]^3]\n",
    "sigma1(x, t; p=params_triad) = (p[5] - p[6] * x[1]) / √2\n",
    "sigma2(x, t; p=params_triad) = p[7] / √2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654941c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Score Functions & Derivatives ---\n",
    "function create_true_score_and_derivative_triad(p)\n",
    "    a, b, c, F_tilde, A, B, s_val = p\n",
    "    num(u) = 2 * (F_tilde + a*u + b*u^2 - c*u^3)\n",
    "    den(u) = s_val^2 + (A - B*u)^2\n",
    "    score_func(x) = num(x) / den(x)\n",
    "    function score_derivative_func(u)\n",
    "        num_deriv = 2 * (a + 2*b*u - 3*c*u^2)\n",
    "        den_deriv = 2 * (A - B*u) * (-B)\n",
    "        return (num_deriv * den(u) - num(u) * den_deriv) / den(u)^2\n",
    "    end\n",
    "    return score_func, score_derivative_func\n",
    "end\n",
    "\n",
    "function create_linear_s_ds(x_t)\n",
    "    μ = mean(x_t)\n",
    "    variance = var(x_t)\n",
    "    score_func(x) = -(x - μ) / variance\n",
    "    score_derivative(x) = -1 / variance\n",
    "    return score_func, score_derivative\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0850c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Divergence Score Construction ---\n",
    "function construct_divergence_score(s::Function; n_points::Int=500, range::Tuple{Real,Real}=(-5.0, 5.0))\n",
    "    x_grid = Base.range(range[1], range[2], length=n_points)\n",
    "    divergence_values = similar(x_grid)\n",
    "    h = 1e-6 # Finite difference step\n",
    "    score_scalar(x) = begin\n",
    "        s_val = s(x)\n",
    "        return s_val isa AbstractArray ? s_val[1] : s_val\n",
    "    end\n",
    "    @threads for i in eachindex(x_grid)\n",
    "        divergence_values[i] = (score_scalar(x_grid[i] + h) - score_scalar(x_grid[i] - h)) / (2 * h)\n",
    "    end\n",
    "    function fast_divergence_func(x_val::Real)\n",
    "        if x_val < range[1] return divergence_values[1] end\n",
    "        if x_val > range[2] return divergence_values[end] end\n",
    "        idx_float = (x_val - range[1]) / step(x_grid) + 1\n",
    "        idx_low = floor(Int, idx_float)\n",
    "        idx_high = min(idx_low + 1, n_points)\n",
    "        idx_low = max(1, idx_low)\n",
    "        t = idx_float - idx_low\n",
    "        return divergence_values[idx_low] * (1 - t) + divergence_values[idx_high] * t\n",
    "    end\n",
    "    return fast_divergence_func\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532d1511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Potentials and Jacobians ---\n",
    "function potential_triad(x, p)\n",
    "    a_p, b_p, c_p, F_tilde_p, A_p, B_p, s_val_p = p\n",
    "    sigma_sq(y) = (A_p - B_p*y)^2 + s_val_p^2\n",
    "    drift(y) = -F_tilde_p + a_p*y + b_p*y^2 - c_p*y^3\n",
    "    integral_part, _ = quadgk(y -> 2 * drift(y) / sigma_sq(y), 0, x, rtol=1e-6)\n",
    "    return -integral_part + log(sigma_sq(x))\n",
    "end\n",
    "p_unnormalized_triad(x, p) = exp(-potential_triad(x, p))\n",
    "function compute_observables_triad(p, observables)\n",
    "    int_bounds = (-6, 6)\n",
    "    norm_const, _ = quadgk(x -> p_unnormalized_triad(x, p), int_bounds..., rtol=1e-8)\n",
    "    if norm_const == 0.0 error(\"Normalization constant is zero. Check potential function or integration bounds.\") end\n",
    "    map(observables) do obs\n",
    "        obs_integral, _ = quadgk(x -> obs(x) * p_unnormalized_triad(x, p), int_bounds..., rtol=1e-8)\n",
    "        obs_integral / norm_const\n",
    "    end\n",
    "end\n",
    "function compute_jacobian_triad(p, param_indices, observables; ε=1e-5)\n",
    "    J = zeros(length(observables), length(param_indices))\n",
    "    for (i, p_idx) in enumerate(param_indices)\n",
    "        p_plus, p_minus = copy(p), copy(p)\n",
    "        p_plus[p_idx] += ε\n",
    "        p_minus[p_idx] -= ε\n",
    "        obs_plus = compute_observables_triad(p_plus, observables)\n",
    "        obs_minus = compute_observables_triad(p_minus, observables)\n",
    "        J[:, i] = (obs_plus - obs_minus) / (2 * ε)\n",
    "    end\n",
    "    return J\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bb14c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Conjugate Observables & Response Matrix ---\n",
    "function create_conjugate_observables_triad(score, score_derivative, p)\n",
    "    A_p, B_p, s_val_p = p[5], p[6], p[7]\n",
    "    s_func(x) = begin\n",
    "        s_val = score(x)\n",
    "        return s_val isa AbstractArray ? s_val[1] : s_val\n",
    "    end\n",
    "    s_prime(x) = begin\n",
    "        s_val = score_derivative(x)\n",
    "        return s_val isa AbstractArray ? s_val[1] : s_val\n",
    "    end\n",
    "    function B_B(x)\n",
    "        s_x = s_func(x)\n",
    "        s_prime_x = s_prime(x)\n",
    "        f_eff_B_val = 0.5 * ((-A_p*x + B_p*x^2) * s_x - A_p + 2*B_p*x)\n",
    "        f_eff_B_prime_val = 0.5 * ((-A_p + 2*B_p*x)*s_x + (-A_p*x + B_p*x^2)*s_prime_x + 2*B_p)\n",
    "        result = -(f_eff_B_prime_val + f_eff_B_val * s_x)\n",
    "        return result isa AbstractArray ? result[1] : result\n",
    "    end\n",
    "    function B_s(x)\n",
    "        s_x = s_func(x)\n",
    "        s_prime_x = s_prime(x)\n",
    "        result = -0.5 * s_val_p * (s_prime_x + s_x^2)\n",
    "        return result isa AbstractArray ? result[1] : result\n",
    "    end\n",
    "    return [B_B, B_s]\n",
    "end\n",
    "\n",
    "function create_response_matrix(time_series, dt, observables, conjugate_observables; max_lag_time=30.0)\n",
    "    lag_indices = 0:floor(Int, max_lag_time / dt)\n",
    "    R = zeros(length(observables), length(conjugate_observables))\n",
    "    obs_ts = [obs.(time_series) for obs in observables]\n",
    "    conj_obs_ts = [c_obs.(time_series) for c_obs in conjugate_observables]\n",
    "    @threads for k in eachindex(observables)\n",
    "        for i in eachindex(conjugate_observables)\n",
    "            corr = crosscov(obs_ts[k], conj_obs_ts[i], lag_indices; demean=true)\n",
    "            R[k, i] = dt * (sum(corr) - 0.5 * (corr[1] + corr[end]))\n",
    "        end\n",
    "    end\n",
    "    return R\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d63729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Sensitivity Analysis and Optimization Routines ---\n",
    "function run_sensitivity_analysis(response_matrix, params_original, param_indices, initial_observables, observables; n_control=100, base_Δμ=nothing, λ=0.1)\n",
    "    N_observables = size(response_matrix, 1)\n",
    "    N_params = length(param_indices)\n",
    "    base_Δμ = isnothing(base_Δμ) ? fill(0.01, N_observables) : base_Δμ\n",
    "    predicted_changes = zeros(N_observables, n_control)\n",
    "    actual_changes = zeros(N_observables, n_control)\n",
    "    A = λ * I(N_params)\n",
    "    for k in 1:n_control\n",
    "        Δμ_k = k * base_Δμ\n",
    "        δc_opt = (response_matrix' * response_matrix + A) \\ (response_matrix' * Δμ_k)\n",
    "        predicted_changes[:, k] = response_matrix * δc_opt\n",
    "        params_new = copy(params_original)\n",
    "        params_new[param_indices] .+= δc_opt\n",
    "        observables_new = compute_observables_triad(params_new, observables)\n",
    "        actual_changes[:, k] = observables_new - initial_observables\n",
    "    end\n",
    "    return predicted_changes, actual_changes\n",
    "end\n",
    "\n",
    "function run_newton_optimization(initial_jacobian, params_original, param_indices, initial_obs, target_obs, observables; max_iters=10, tolerance=1e-4, λ=0.1, recalculate_jacobian=false, jacobian_method=:response_matrix, score_type=:true, sim_dt=0.01, sim_steps=10_000_000)\n",
    "    method_name = recalculate_jacobian ? \"Full Newton ($jacobian_method, $score_type)\" : \"Quasi-Newton\"\n",
    "    println(\"\\n--- Starting Optimization: $method_name ---\")\n",
    "    curr_params = copy(params_original)\n",
    "    curr_observables = copy(initial_obs)\n",
    "    observables_history = [copy(curr_observables)]\n",
    "    jacobian = copy(initial_jacobian)\n",
    "    A = λ * I(length(param_indices))\n",
    "    for iter in 1:max_iters\n",
    "        println(\"--- Iteration $iter ---\")\n",
    "        if recalculate_jacobian && iter > 1\n",
    "            println(\"Recalculating Jacobian/Response Matrix...\")\n",
    "            if jacobian_method == :analytical_jacobian\n",
    "                jacobian = compute_jacobian_triad(curr_params, param_indices, observables)\n",
    "            else # :response_matrix\n",
    "                F_curr(x,t) = F(x,t; p=curr_params); s1_curr(x,t) = sigma1(x,t; p=curr_params); s2_curr(x,t) = sigma2(x,t; p=curr_params);\n",
    "                new_ts = evolve([0.0], sim_dt, sim_steps, F_curr, s1_curr, s2_curr; timestepper=:rk4)[1,:]\n",
    "                score_func, score_deriv_func = if score_type == :true\n",
    "                    create_true_score_and_derivative_triad(curr_params)\n",
    "                elseif score_type == :linear\n",
    "                    create_linear_s_ds(new_ts)\n",
    "                else # :kgmm\n",
    "                    kgmm = calculate_score_kgmm(reshape(new_ts, 1, :); σ_value=0.05, verbose=false)\n",
    "                    kgmm.score_function, construct_divergence_score(kgmm.score_function)\n",
    "                end\n",
    "                conjugates = create_conjugate_observables_triad(score_func, score_deriv_func, curr_params)\n",
    "                jacobian = create_response_matrix(new_ts, sim_dt, observables, conjugates)\n",
    "            end\n",
    "            println(\"Updated Matrix:\"); display(jacobian)\n",
    "        end\n",
    "        residual = target_obs - curr_observables\n",
    "        if norm(residual) < tolerance\n",
    "            println(\"Target reached within tolerance.\"); break\n",
    "        end\n",
    "        δc = (jacobian' * jacobian + A) \\ (jacobian' * residual)\n",
    "        curr_params[param_indices] .+= δc\n",
    "        curr_observables = compute_observables_triad(curr_params, observables)\n",
    "        push!(observables_history, copy(curr_observables))\n",
    "        println(\"New observables (Mean, <x^2>): $(round.(curr_observables, digits=5))\")\n",
    "    end\n",
    "    return observables_history\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9955be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generate Baseline Time Series Data ---\n",
    "dt_sim = 0.01\n",
    "N_steps = 20_000_000\n",
    "time_series_triad = evolve([0.0], dt_sim, N_steps, F, sigma1, sigma2; timestepper=:rk4)[1,:]\n",
    "println(\"Data generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b48badc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute Response Matrices and Jacobian ---\n",
    "observables_to_control = [x -> x, x -> x^2]\n",
    "observable_labels = [\"Mean\", \"Variance\"]\n",
    "param_indices_to_control = [6, 7]\n",
    "param_labels = [\"δB\", \"δs_noise\"]\n",
    "initial_observables = compute_observables_triad(params_triad, observables_to_control)\n",
    "initial_variance = initial_observables[2] - initial_observables[1]^2\n",
    "println(\"Initial Observables (Mean, <x^2>): $initial_observables\")\n",
    "println(\"Initial Variance: $initial_variance\")\n",
    "\n",
    "# True score\n",
    "true_score, true_score_deriv = create_true_score_and_derivative_triad(params_triad)\n",
    "conjugate_obs_true = create_conjugate_observables_triad(true_score, true_score_deriv, params_triad)\n",
    "R_true = create_response_matrix(time_series_triad, dt_sim, observables_to_control, conjugate_obs_true)\n",
    "\n",
    "# Linear score\n",
    "linear_score, linear_score_deriv = create_linear_s_ds(time_series_triad)\n",
    "conjugate_obs_linear = create_conjugate_observables_triad(linear_score, linear_score_deriv, params_triad)\n",
    "R_linear = create_response_matrix(time_series_triad, dt_sim, observables_to_control, conjugate_obs_linear)\n",
    "\n",
    "# Clustered (KGMM) score\n",
    "kgmm_results = calculate_score_kgmm(reshape(time_series_triad, 1, :); σ_value=0.05, clustering_prob=0.0005, verbose=false)\n",
    "score_clustered = kgmm_results.score_function\n",
    "score_clustered_derivative = construct_divergence_score(score_clustered)\n",
    "conjugate_obs_clustered = create_conjugate_observables_triad(score_clustered, score_clustered_derivative, params_triad)\n",
    "R_clustered = create_response_matrix(time_series_triad, dt_sim, observables_to_control, conjugate_obs_clustered)\n",
    "\n",
    "# Analytical Jacobian\n",
    "J_analytical = compute_jacobian_triad(params_triad, param_indices_to_control, observables_to_control; ε=1e-4)\n",
    "\n",
    "println(\"Response Matrix R (from true score):\"); display(R_true)\n",
    "println(\"Response Matrix R (from linear score):\"); display(R_linear)\n",
    "println(\"Response Matrix R (from clustered/KGMM score):\"); display(R_clustered)\n",
    "println(\"Jacobian J (from analytic PDF):\"); display(J_analytical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7d991c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run Newton's Method Optimization ---\n",
    "target_mean = initial_observables[1] - 0.1\n",
    "target_variance = initial_variance * 0.9\n",
    "target_x_squared = target_variance + target_mean^2\n",
    "target_observables = [target_mean, target_x_squared]\n",
    "println(\"Target Observables (Mean, <x^2>): $target_observables\")\n",
    "common_args = (params_triad, param_indices_to_control, initial_observables, target_observables, observables_to_control)\n",
    "newton_kwargs = (max_iters=8, λ=0.01)\n",
    "obs_hist_J_quasi = run_newton_optimization(J_analytical, common_args...; newton_kwargs...)\n",
    "obs_hist_R_true_quasi = run_newton_optimization(R_true, common_args...; newton_kwargs...)\n",
    "obs_hist_R_linear_quasi = run_newton_optimization(R_linear, common_args...; newton_kwargs...)\n",
    "obs_hist_R_clustered_quasi = run_newton_optimization(R_clustered, common_args...; newton_kwargs...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6d5a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot Results with Makie ---\n",
    "GLMakie.activate!()\n",
    "get_mean(history) = [h[1] for h in history]\n",
    "get_var(history) = [h[2] - h[1]^2 for h in history]\n",
    "fig = Figure(size=(1600, 700), fontsize=20)\n",
    "ga = fig[1, 1] = GridLayout()\n",
    "ax1 = Axis(ga[1, 1], xlabel=\"Iteration\", ylabel=\"Mean\", title=\"Convergence of Mean\")\n",
    "lines!(ax1, 0:length(obs_hist_J_quasi)-1, get_mean(obs_hist_J_quasi), label=\"Jacobian\", linewidth=3, color=:purple)\n",
    "lines!(ax1, 0:length(obs_hist_R_true_quasi)-1, get_mean(obs_hist_R_true_quasi), label=\"True Score\", linewidth=3, color=:blue)\n",
    "lines!(ax1, 0:length(obs_hist_R_linear_quasi)-1, get_mean(obs_hist_R_linear_quasi), label=\"Linear Score\", linewidth=3, color=:green)\n",
    "lines!(ax1, 0:length(obs_hist_R_clustered_quasi)-1, get_mean(obs_hist_R_clustered_quasi), label=\"KGMM Score\", linewidth=3, color=:orange)\n",
    "hlines!(ax1, [target_mean], color=:red, linestyle=:dash, label=\"Target\")\n",
    "ax2 = Axis(ga[1, 2], xlabel=\"Iteration\", ylabel=\"Variance\", title=\"Convergence of Variance\")\n",
    "lines!(ax2, 0:length(obs_hist_J_quasi)-1, get_var(obs_hist_J_quasi), label=\"Jacobian\", linewidth=3, color=:purple)\n",
    "lines!(ax2, 0:length(obs_hist_R_true_quasi)-1, get_var(obs_hist_R_true_quasi), label=\"True Score\", linewidth=3, color=:blue)\n",
    "lines!(ax2, 0:length(obs_hist_R_linear_quasi)-1, get_var(obs_hist_R_linear_quasi), label=\"Linear Score\", linewidth=3, color=:green)\n",
    "lines!(ax2, 0:length(obs_hist_R_clustered_quasi)-1, get_var(obs_hist_R_clustered_quasi), label=\"KGMM Score\", linewidth=3, color=:orange)\n",
    "hlines!(ax2, [target_variance], color=:red, linestyle=:dash, label=\"Target\")\n",
    "Legend(ga[1, 3], ax1, \"Method\")\n",
    "display(fig)\n",
    "CairoMakie.activate!()\n",
    "save(\"triad_model_full_analysis.pdf\", fig)\n",
    "println(\"✅ Figure saved to triad_model_full_analysis.pdf\")\n",
    "GLMakie.activate!()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.6",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
